{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2702930a",
   "metadata": {},
   "source": [
    "## 01 - Tokenização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0fffe98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'IA', 'está', 'ajudando', 'em', 'automatizações', 'na', 'industria', '.']\n"
     ]
    }
   ],
   "source": [
    "texto = \"A IA está ajudando em automatizações na industria.\"\n",
    "tokens = texto.replace(\".\", \" .\").split()\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8d59ac",
   "metadata": {},
   "source": [
    "## 02 - Stopwords - Remoção de Stopwords com spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "817d28b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['IA', 'ajudando', 'setores', 'industria', 'vendas', 'marketing', 'logística']\n"
     ]
    }
   ],
   "source": [
    "# Instalar o spaCy com o código: pip install -q spacy\n",
    "\n",
    "# Baixa o modelo pequeno de português com o código:  python -m spacy download pt_core_news_sm\n",
    "\n",
    "# Carregando o modelo\n",
    "import spacy\n",
    "nlp = spacy.load(\"pt_core_news_sm\")\n",
    "\n",
    "texto = \"A IA está ajudando em todos os setores da industria, como vendas, marketing, logística entre outros.\"\n",
    "doc = nlp(texto)\n",
    "\n",
    "conteudo = [t.text for t in doc if not t.is_stop and t.is_alpha]\n",
    "print(conteudo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0b724f",
   "metadata": {},
   "source": [
    "## 03 - Part-of-Speech (POS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3f12f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A DET DET\n",
      "IA PROPN PROPN\n",
      "está AUX AUX\n",
      "ajudando VERB VERB\n",
      "nos ADP ADP\n",
      "avanços NOUN NOUN\n",
      "das ADP ADP\n",
      "pesquisas NOUN NOUN\n",
      "científicas ADJ ADJ\n",
      ". PUNCT PUNCT\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.symbols import POS\n",
    "\n",
    "nlp = spacy.load(\"pt_core_news_sm\")\n",
    "\n",
    "for token in nlp(\"A IA está ajudando nos avanços das pesquisas científicas.\"):\n",
    "    print(token.text, token.pos_, token.tag_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f735b47c",
   "metadata": {},
   "source": [
    "## 04 - Stemização (Stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f54202c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['faz', 'faz', 'feit', 'dou']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package rslp to\n",
      "[nltk_data]     C:\\Users\\84284528572\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import RSLPStemmer\n",
    "\n",
    "nltk.download('rslp')\n",
    "\n",
    "stemmer = RSLPStemmer()\n",
    "palavras = [\"Fazer\", \"Fazendo\", \"Feito\", \"Doutores\"]\n",
    "\n",
    "print([stemmer.stem(p) for p in palavras])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cd0113",
   "metadata": {},
   "source": [
    "## 05 - Lematização (Lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97bddb51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('IA', 'IA'), ('vem', 'vir'), ('ajudando', 'ajudar'), ('a', 'a'), ('automatizar', 'automatizar'), ('processos', 'processo'), ('administrativos', 'administrativo'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"pt_core_news_sm\")\n",
    "\n",
    "frase = \"IA vem ajudando a automatizar processos administrativos.\"\n",
    "print([(t.text, t.lemma_) for t in nlp(frase)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf2387a",
   "metadata": {},
   "source": [
    "## 06 - Entidades nomeadas (NER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9af1f2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Universidade SENAI ORG\n",
      "Universidade da USP LOC\n",
      "REMAMA MISC\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"pt_core_news_sm\")\n",
    "\n",
    "texto = \"O Universidade SENAI e a Universidade da USP iniciaram um projeto com as meninas do REMAMA.\"\n",
    "doc = nlp(texto)\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07ad431",
   "metadata": {},
   "source": [
    "## 07 - Análise sintática (dependências)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c298916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IA nsubj vem\n",
      "vem ROOT vem\n",
      "ajudando xcomp vem\n",
      "a mark automatizar\n",
      "automatizar xcomp ajudando\n",
      "processos obj automatizar\n",
      "administrativos amod processos\n",
      "com case maestria\n",
      "grande amod maestria\n",
      "maestria nmod processos\n",
      ". punct vem\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"pt_core_news_sm\")\n",
    "\n",
    "doc = nlp(\"IA vem ajudando a automatizar processos administrativos com grande maestria.\")\n",
    "for token in doc:\n",
    "    print(token.text, token.dep_, token.head.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec92bff",
   "metadata": {},
   "source": [
    "## 08 - Noun Chunks (grupos nominais)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f903537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A IA\n",
      "automatizações\n",
      "industria\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"pt_core_news_sm\")\n",
    "\n",
    "doc = nlp(\"A IA está ajudando em automatizações na industria.\")\n",
    "for chunk in doc.noun_chunks:\n",
    "    print(chunk.text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe25297",
   "metadata": {},
   "source": [
    "## 09 - Busca por semelhanças"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d0b42ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, np.float64(1.0)), (1, np.float64(0.4162752553793451)), (2, np.float64(0.33417258376902))]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Corpus de exemplo\n",
    "corpus = [\n",
    "    \"A IA está ajudando em automatizações na industria\",\n",
    "    \"A IA está revolucionando a industria com automatizações\",\n",
    "    \"Automatizações na industria estão sendo impulsionadas pela IA\",\n",
    "]\n",
    "\n",
    "vec = TfidfVectorizer()\n",
    "X = vec.fit_transform(corpus)\n",
    "\n",
    "# Similaridade entre a frase 0 e as demais\n",
    "sims = cosine_similarity(X[0], X).flatten()\n",
    "print(list(enumerate(sims)))\n",
    "\n",
    "# Valores próximos de 1 => mais parecidos; próximos de 0 => diferentes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27dc6cdd",
   "metadata": {},
   "source": [
    "## 10 - Expressões regulares (regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3167a731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alandiekguimaraes@gmail.com']\n",
      "['#UniSenai']\n",
      "['29', '2025']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "texto = \"Contato: alandiekguimaraes@gmail.com no evento #UniSenai dia 29 de novembro de 2025\"\n",
    "print(re.findall(r\"\\b[\\w.-]+@[\\w.-]+\\.[a-zA-Z]{2,}\\b\", texto))\n",
    "print(re.findall(r\"#\\w+\", texto))\n",
    "print(re.findall(r\"\\b\\d+\\b\", texto))\n",
    "\n",
    "# Saída:\n",
    "# ['maria.silva@exemplo.com']\n",
    "# ['#PNL']\n",
    "# ['12']\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
